"""FastAPI server for GroundedDINO-VL Label Studio ML Backend.

Endpoints:
  - GET /health: basic health with model-loaded flag
  - POST /predict: accept Label Studio task JSON (image URL or base64),
                   run inference, return LS-formatted predictions
  - GET /model-info: return model metadata

Notes:
  - CORS is enabled for all origins.
  - Default port is 9090 (configurable via DEFAULT_SETTINGS.server_port or PORT env).
"""

from __future__ import annotations

from typing import Any, Dict, List, Union
import argparse
import base64
import os
from urllib.request import urlopen, Request

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware

from .config import DEFAULT_SETTINGS
from . import model_loader
from . import inference_engine


def _read_bytes_from_url(url: str, timeout: int = 20) -> bytes:
    req = Request(url, headers={"User-Agent": "Mozilla/5.0"})
    with urlopen(req, timeout=timeout) as resp:
        return resp.read()


def _maybe_extract_image_ref(task: Dict[str, Any]) -> Union[str, bytes, None]:
    """Extract an image reference from a Label Studio-like task.

    Returns one of:
      - bytes (if already provided)
      - str URL or data URI
      - None if not found
    """
    # Common fields: direct at root
    for key in ("image_bytes", "image", "image_url", "imageUrl", "img", "url"):
        if key in task:
            return task[key]

    # Under "data" (Label Studio style)
    data = task.get("data") if isinstance(task.get("data"), dict) else {}
    for key in ("image", "image_url", "imageUrl", "img", "url", "image_bytes"):
        if key in data:
            return data[key]

    return None


def _extract_prompt(task: Dict[str, Any]) -> Union[str, List[str]]:
    """Extract labeling instructions/caption/classes from task.

    Heuristics looking at several common fields. Falls back to a generic caption.
    """
    # Prefer explicit prompt at root
    for key in ("prompt", "caption", "instruction", "instructions"):
        if key in task and task[key]:
            return task[key]

    data = task.get("data") if isinstance(task.get("data"), dict) else {}
    for key in ("prompt", "caption", "text", "instruction", "classes"):
        if key in data and data[key]:
            return data[key]

    # Label list
    for key in ("labels", "classes"):
        if key in task and task[key]:
            return task[key]

    return "a photo"


def _to_image_bytes(ref: Union[str, bytes]) -> bytes:
    if isinstance(ref, (bytes, bytearray)):
        return bytes(ref)
    if not isinstance(ref, str):
        raise ValueError("Unsupported image reference type")

    s = ref.strip()
    # Data URI: data:image/...;base64,XXXXX
    if s.startswith("data:image/") and ";base64," in s:
        b64 = s.split(",", 1)[1]
        return base64.b64decode(b64)

    # Plain base64 without data URI (heuristic: long and only base64 chars)
    if len(s) > 256 and all(c.isalnum() or c in "+/=_-" for c in s[:300]):
        try:
            return base64.b64decode(s)
        except Exception:
            pass

    # Otherwise treat as URL
    if s.startswith("http://") or s.startswith("https://"):
        return _read_bytes_from_url(s)

    # Treat as filesystem path as a last resort
    if os.path.isfile(s):
        with open(s, "rb") as f:
            return f.read()

    raise ValueError("Unrecognized image reference; expected URL, base64, or bytes")


def create_app() -> Any:
    """Create and return the FastAPI web application instance."""
    app = FastAPI(
        title="GroundedDINO-VL LS Backend",
        version=str(model_loader.get_model_info().get("version", "unknown")),
    )

    # CORS: allow all
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # Optional database initialization (no side effects unless explicitly enabled)
    try:
        use_pg = os.environ.get("USE_POSTGRESQL", "").lower() == "true"
        sqlite_path = os.environ.get("SQLITE_PATH")
        if use_pg or sqlite_path:
            # Lazy import so environments without SQLAlchemy can still run server/tests
            from . import database  # type: ignore

            # Will select the proper URL based on env vars
            database.init_db(echo=False)
    except Exception as e:
        # Do not prevent server from running if DB init fails; keep it optional.
        # Basic visibility only; avoid introducing logging dependencies here.
        print(f"[ls_backend] Optional DB initialization skipped/failed: {e}")

    @app.get("/health")
    def health() -> Dict[str, Any]:
        info = model_loader.get_model_info()
        model_loaded = bool(info.get("config_path") and info.get("checkpoint_path"))
        # If not explicitly loaded yet, detect bundled default model files
        if not model_loaded:
            try:
                # server.py is at groundeddino_vl/ls_backend/server.py
                # repo root is two levels up from here
                project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
                default_config = os.environ.get(
                    "MODEL_CONFIG_PATH",
                    os.path.join(
                        project_root,
                        "groundeddino_vl",
                        "models",
                        "configs",
                        "GroundingDINO_SwinT_OGC.py",
                    ),
                )
                default_ckpt = os.environ.get(
                    "MODEL_CHECKPOINT_PATH",
                    os.path.join(project_root, "checkpoints", "groundingdino_swint_ogc.pth"),
                )
                if os.path.isfile(default_config) and os.path.isfile(default_ckpt):
                    model_loaded = True
            except Exception:
                # Be conservative: keep previous value
                pass
        return {"status": "ok", "model_loaded": model_loaded}

    @app.get("/model-info")
    def model_info() -> Dict[str, Any]:
        return model_loader.get_model_info()

    @app.post("/predict")
    def predict(task: Union[Dict[str, Any], List[Dict[str, Any]]]) -> List[Any]:
        tasks: List[Dict[str, Any]]
        if isinstance(task, list):
            tasks = task
        elif isinstance(task, dict):
            tasks = [task]
        else:
            raise HTTPException(
                status_code=400, detail="Invalid JSON body; expected object or list"
            )

        predictions: List[Any] = []
        for t in tasks:
            img_ref = _maybe_extract_image_ref(t)
            if img_ref is None:
                raise HTTPException(status_code=400, detail="No image reference found in task")
            try:
                image_bytes = _to_image_bytes(img_ref)
            except Exception as e:
                raise HTTPException(status_code=400, detail=f"Failed to obtain image bytes: {e}")

            prompt = _extract_prompt(t)
            try:
                result = inference_engine.run_inference(image_bytes=image_bytes, prompt_text=prompt)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Inference failed: {e}")

            # Append LS-formatted prediction list for this task
            predictions.append(result["labelstudio"])

        return predictions if len(tasks) > 1 else predictions[0]

    return app


def main() -> None:
    """CLI entry point to start the server with uvicorn.

    Supports optional command-line overrides for host and port, e.g.:
      python -m groundeddino_vl.ls_backend.server --host 0.0.0.0 --port 9090
    """
    try:
        import uvicorn  # type: ignore
    except Exception as e:  # pragma: no cover
        raise RuntimeError(
            "uvicorn is required to run the server. Install with `pip install uvicorn`."
        ) from e

    parser = argparse.ArgumentParser(description="GroundedDINO-VL LS Backend Server")
    parser.add_argument(
        "--host", default=os.environ.get("HOST", "0.0.0.0"), help="Host interface to bind"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=int(os.environ.get("PORT", str(getattr(DEFAULT_SETTINGS, "server_port", 9090)))),
        help="TCP port to listen on",
    )
    args = parser.parse_args()

    uvicorn.run(
        "groundeddino_vl.ls_backend.server:create_app",
        host=args.host,
        port=args.port,
        factory=True,
    )


if __name__ == "__main__":  # pragma: no cover
    main()
